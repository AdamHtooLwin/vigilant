device: cuda:3

show_imgs: False
print_model: False

loss_coef:  # coefficients for losses
  clf_loss: 5.0
  reg_loss: 5.0
  trip_loss: 1.0

# TODO: config for optimizer
lr: 0.0001  # optimizer lr
# TODO: config for scheduler
milestones:  # MultiStepLR scheduler params
  - 5
  - 8
  - 12
gamma: 0.3

image_size: 224  # size of input image
cue_log_every_epoch: True  # will log cues every cue_log_every batches. If 0, than won't log
mean:
  r: 0
  g: 0
  b: 0
std:
  r: 1
  g: 1
  b: 1

#mean:
#  r: 0.485
#  g: 0.456
#  b: 0.406
#std:
#  r: 0.229
#  g: 0.224
#  b: 0.225

# uncomment this, to use online face cropping
# however it is not recommended
# you can only use cpu device as device for face-cropping nn
#face_detector:
#  image_size: 512
#  margin: 100
#  min_face_size: 100
#  thresholds: [0.6, 0.7, 0.7]
#  factor: 0.709
#  device: *device

train_df: "/root/datasets/siwm/train_labels.csv"  # path to train csv file
val_df: "/root/datasets/siwm/test_labels.csv"  # path to validation csv file
path_root: "/root/datasets/siwm"  # prefix path to your images

batch_size: 64  # batch size for both validation and train dataloader
num_workers_train: 0  # param for training dataloader
num_workers_val: 0  # param for validation dataloader

log_dir: "/root/vigilant/logs/siwm/"  # path to save pytorch_lightning logs
max_epochs: 25  # max number of epochs to train (if doesn't achieved early stopping)

use_balance_sampler: False  # You can try overcome class disbalance using balance sampler
use_focal_loss: False  # You can try use focal loss instead of cross-entropy loss