#device: &device cpu
gpu: 2

show_imgs: False

loss_coef:  # coefficients for losses
  clf_loss: 5.0
  reg_loss: 5.0
  trip_loss: 1.0

# TODO: config for optimizer
lr: 0.0005  # optimizer lr
# TODO: config for scheduler
milestones:  # MultiStepLR scheduler params
  - 5
  - 8
  - 12
gamma: 0.3

image_size: 224  # size of input image
cue_log_every: 500  # will log cues every cue_log_every batches. If 0, than won't log
#mean:
#  r: 100
#  g: 100
#  b: 100
#std:
#  r: 80
#  g: 80
#  b: 80

mean:
  r: 0
  g: 0
  b: 0
std:
  r: 1
  g: 1
  b: 1

#mean:
#  r: 0.485
#  g: 0.456
#  b: 0.406
#std:
#  r: 0.229
#  g: 0.224
#  b: 0.225

# uncomment this, to use online face cropping
# however it is not recommended
# you can only use cpu device as device for face-cropping nn
#face_detector:
#  image_size: 512
#  margin: 100
#  min_face_size: 100
#  thresholds: [0.6, 0.7, 0.7]
#  factor: 0.709
#  device: *device

train_df: "/root/datasets/oulu/Protocols/Protocol_4/train_6.csv"  # path to train csv file
val_df: "/root/datasets/oulu/Protocols/Protocol_4/dev_6.csv"  # used test because dev has same session
test_df: "/root/datasets/oulu/Protocols/Protocol_4/test_6.csv"  # used test because dev has same session
path_root: "/root/datasets/oulu"  # prefix path to your images

batch_size: 32  # batch size for both validation and train dataloader
num_workers_train: 0  # param for training dataloader
num_workers_val: 0  # param for validation dataloader

default_root_dir: "/root/lgsc/logs/oulu/protocol_4"  # path to save pytorch_lightning logs
max_epochs: 30  # max number of epochs to train (if doesn't achieved early stopping)

use_balance_sampler: False  # You can try overcome class disbalance using balance sampler
use_weighted_sampler: False  # You can try overcome class disbalance using weighted sampler
use_focal_loss: False  # You can try use focal loss instead of cross-entropy loss